{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ffb005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data colelction and Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e55bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # Importing OpenCV library for computer vision tasks\n",
    "from cvzone.HandTrackingModule import HandDetector  # Importing HandDetector module from cvzone library\n",
    "import numpy as np  # Importing NumPy library for numerical operations\n",
    "import math  # Importing math library for mathematical operations\n",
    "import time  # Importing time library for time-related functions\n",
    "\n",
    "# Open the default camera (index 0)\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Initializing HandDetector object with maximum hands to detect set to 2 for detecting both hands\n",
    "handDetector = HandDetector(maxHands=2)\n",
    "\n",
    "# Define an offset for cropping the hand region\n",
    "cropOffset = 20\n",
    "\n",
    "# Define the size of the output image\n",
    "imageSize = 300\n",
    "\n",
    "# Define the folder to save the captured images\n",
    "savefolder = \"Data/A\"  # Define the folder to save the captured images\n",
    "\n",
    "# Counter to keep track of the number of captured images\n",
    "counter = 0\n",
    "\n",
    "# Infinite loop to continuously capture frames from the camera\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    suc, image = capture.read()\n",
    "\n",
    "    # Detect hands in the frame\n",
    "    hands, _ = handDetector.findHands(image)\n",
    "\n",
    "    # If hands are detected\n",
    "    if hands:\n",
    "        # Loop through each detected hand\n",
    "        for hand in hands:\n",
    "            # Extract bounding box coordinates of the hand\n",
    "            x, y, w, h = hand['bbox']\n",
    "\n",
    "            # Create a white image with the specified size\n",
    "            imageWhite = np.ones((imageSize, imageSize, 3), np.uint8) * 255\n",
    "\n",
    "            # Crop the hand region from the frame\n",
    "            imgageCrop = image[y - cropOffset:y + h + cropOffset, x - cropOffset:x + w + cropOffset]\n",
    "\n",
    "            # Calculate the aspect ratio of the hand region\n",
    "            aspRatio = h / w\n",
    "\n",
    "            # If the aspect ratio is greater than 1, resize based on height\n",
    "            if aspRatio > 1:\n",
    "                k = imageSize / h\n",
    "                widthCal = math.ceil(k * w)\n",
    "                imgResize = cv2.resize(imgageCrop, (widthCal, imageSize))\n",
    "                widthGap = math.ceil((imageSize - widthCal) / 2)\n",
    "                imageWhite[:, widthGap:widthCal + widthGap] = imgResize\n",
    "            # If the aspect ratio is less than or equal to 1, resize based on width\n",
    "            else:\n",
    "                k = imageSize / w\n",
    "                heightCal = math.ceil(k * h)\n",
    "                imageResize = cv2.resize(imgageCrop, (imageSize, heightCal))\n",
    "                heightGap = math.ceil((imageSize - heightCal) / 2)\n",
    "                imageWhite[heightGap:heightCal + heightGap, :] = imageResize\n",
    "\n",
    "            # Display the resized hand image on a white background\n",
    "            cv2.imshow(\"ImageWhite\", imageWhite)\n",
    "\n",
    "    # Display the original frame\n",
    "    cv2.imshow(\"Image\", image)\n",
    "\n",
    "    # Wait for a key event and check if 's' is pressed\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"s\"):\n",
    "        # Increment the counter\n",
    "        counter += 1\n",
    "        # Save the cropped hand images with a timestamp as the filename\n",
    "        for hand_index, hand in enumerate(hands):\n",
    "            hand_image = hand['img']\n",
    "            cv2.imwrite(f'{savefolder}/Hand_{hand_index}_Image_{time.time()}.jpg', hand_image)\n",
    "        # Print the current count of saved images\n",
    "        print(counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a104497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST THE DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cfa4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # Importing OpenCV library for computer vision tasks\n",
    "from cvzone.HandTrackingModule import HandDetector  # Importing HandDetector module from cvzone library\n",
    "from cvzone.ClassificationModule import Classifier  # Importing Classifier module from cvzone library\n",
    "import numpy as np  # Importing NumPy library for numerical operations\n",
    "import math  # Importing math library for mathematical operations\n",
    "\n",
    "# Open the default camera (index 0)\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Initializing HandDetector object with maximum hands to detect set to 2 for detecting both hands\n",
    "detector = HandDetector(maxHands=2)\n",
    "\n",
    "# Initializing Classifier object with the pre-trained model and labels\n",
    "classifier = Classifier(\"Model/keras_model.h5\", \"Model/labels.txt\")\n",
    "\n",
    "# Define an offset for cropping the hand region\n",
    "crop_offset = 20\n",
    "\n",
    "# Define the size of the output image\n",
    "image_size = 300\n",
    "\n",
    "# Define the folder to save the captured images\n",
    "save_folder = \"Data/C\"\n",
    "\n",
    "# Counter to keep track of the number of captured images\n",
    "counter = 0\n",
    "\n",
    "# Labels for classification\n",
    "labels = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "\n",
    "# Infinite loop to continuously capture frames from the camera\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    success, image = capture.read()\n",
    "\n",
    "    # Create a copy of the original frame for output visualization\n",
    "    image_output = image.copy()\n",
    "\n",
    "    # Detect hands in the frame\n",
    "    hands, image = detector.findHands(image)\n",
    "\n",
    "    # If hands are detected\n",
    "    if hands:\n",
    "        # Loop through each detected hand\n",
    "        for hand in hands:\n",
    "            # Extract bounding box coordinates of the hand\n",
    "            x, y, w, h = hand['bbox']\n",
    "\n",
    "            # Create a white image with the specified size\n",
    "            image_white = np.ones((image_size, image_size, 3), np.uint8) * 255\n",
    "\n",
    "            # Crop the hand region from the frame\n",
    "            image_cropped = image[y - crop_offset:y + h + crop_offset, x - crop_offset:x + w + crop_offset]\n",
    "\n",
    "            # Calculate the aspect ratio of the hand region\n",
    "            aspect_ratio = h / w\n",
    "\n",
    "            # If the aspect ratio is greater than 1, resize based on height\n",
    "            if aspect_ratio > 1:\n",
    "                k = image_size / h\n",
    "                width_cal = math.ceil(k * w)\n",
    "                image_resize = cv2.resize(image_cropped, (width_cal, image_size))\n",
    "                width_gap = math.ceil((image_size - width_cal) / 2)\n",
    "                image_white[:, width_gap:width_cal + width_gap] = image_resize\n",
    "            # If the aspect ratio is less than or equal to 1, resize based on width\n",
    "            else:\n",
    "                k = image_size / w\n",
    "                height_cal = math.ceil(k * h)\n",
    "                image_resize = cv2.resize(image_cropped, (image_size, height_cal))\n",
    "                height_gap = math.ceil((image_size - height_cal) / 2)\n",
    "                image_white[height_gap:height_cal + height_gap, :] = image_resize\n",
    "\n",
    "            # Get prediction and index from the classifier\n",
    "            prediction, index = classifier.getPrediction(image_white, draw=False)\n",
    "\n",
    "            # Draw rectangle and label on the output image\n",
    "            cv2.rectangle(image_output, (x - crop_offset, y - crop_offset - 50), (x - crop_offset + 90, y - crop_offset - 50 + 50),\n",
    "                          (255, 0, 255), cv2.FILLED)\n",
    "            cv2.putText(image_output, labels[index], (x, y - 26), cv2.FONT_HERSHEY_COMPLEX, 1.7, (255, 255, 255), 2)\n",
    "            cv2.rectangle(image_output, (x - crop_offset, y - crop_offset), (x + w + crop_offset, y + h + crop_offset), (255, 0, 255), 4)\n",
    "\n",
    "    # Display the output frame\n",
    "    cv2.imshow(\"Image\", image_output)\n",
    "\n",
    "    # Wait for a key event to exit the loop\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"q\"):\n",
    "        break  # Break the loop if 'q' key is pressed\n",
    "\n",
    "    # Wait for a key event and check if 's' is pressed\n",
    "    elif key == ord(\"s\"):\n",
    "        # Increment the counter\n",
    "        counter += 1\n",
    "        # Save the captured image with a timestamp as the filename\n",
    "        cv2.imwrite(f'{save_folder}/Image_{counter}_{time.time()}.jpg', image_output)\n",
    "        # Print the current count of saved images\n",
    "        print(counter)\n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
